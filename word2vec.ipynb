{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import codecs\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'data/Book 1 - The Philosopher's Stone_djvu.txt'...\n",
      "Corpus is now 474429 characters long\n",
      "Reading 'data/Book 2 - The Chamber of Secrets_djvu.txt'...\n",
      "Corpus is now 1006137 characters long\n",
      "Reading 'data/Book 3 - The Prisoner of Azkaban_djvu.txt'...\n",
      "Corpus is now 1683115 characters long\n",
      "Reading 'data/Book 4 - The Goblet of Fire_djvu.txt'...\n",
      "Corpus is now 2870365 characters long\n",
      "Reading 'data/Book 5 - The Order of the Phoenix_djvu.txt'...\n",
      "Corpus is now 4479128 characters long\n",
      "Reading 'data/Book 6 - The Half Blood Prince_djvu.txt'...\n",
      "Corpus is now 5538150 characters long\n",
      "Reading 'data/Book 7 - The Deathly Hallows_djvu.txt'...\n",
      "Corpus is now 6765174 characters long\n"
     ]
    }
   ],
   "source": [
    "filename = sorted(glob.glob(\"data/*.txt\"))\n",
    "# filename = \"data/got1.txt\"\n",
    "# raw_text = codecs.open(filename, \"r\", \"utf-8\").read()\n",
    "# raw_text = raw_text.lower()\n",
    "\n",
    "raw_text = u\"\"\n",
    "for book_filename in filename:\n",
    "    print \"Reading '{0}'...\".format(book_filename)\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        raw_text += book_file.read()\n",
    "    print \"Corpus is now {0} characters long\".format(len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert into a list of words\n",
    "#remove unnnecessary,, split into words, no hyphens\n",
    "#list of words\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sentence where each word is tokenized\n",
    "words = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        words.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'The',\n",
       " u'Dursley',\n",
       " u's',\n",
       " u'had',\n",
       " u'a',\n",
       " u'small',\n",
       " u'son',\n",
       " u'called',\n",
       " u'Dudley',\n",
       " u'and',\n",
       " u'in',\n",
       " u'their',\n",
       " u'opinion',\n",
       " u'there',\n",
       " u'was',\n",
       " u'no',\n",
       " u'finer',\n",
       " u'boy',\n",
       " u'anywhere']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dursley s had a small son \n",
      "called Dudley and in their opinion there was no finer \n",
      "boy anywhere.\n",
      "[u'The', u'Dursley', u's', u'had', u'a', u'small', u'son', u'called', u'Dudley', u'and', u'in', u'their', u'opinion', u'there', u'was', u'no', u'finer', u'boy', u'anywhere']\n"
     ]
    }
   ],
   "source": [
    "print raw_sentences[5]\n",
    "print sentence_to_wordlist(raw_sentences[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book corpus contains 1,174,677 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(word) for word in words])\n",
    "print \"The book corpus contains {0:,} tokens\".format(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(words, min_count=1, size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model/got1model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load('model/got1model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Philosophers', 0.980586588382721),\n",
       " (u'Deathly', 0.9794279336929321),\n",
       " (u'Hallows', 0.9742118716239929),\n",
       " (u'Half', 0.9741803407669067),\n",
       " (u'Stone', 0.9658727049827576),\n",
       " (u'Phoenix', 0.9649447798728943),\n",
       " (u'Goblet', 0.9637167453765869),\n",
       " (u'Prince', 0.9578150510787964),\n",
       " (u'Fire', 0.9571500420570374),\n",
       " (u'Prisoner', 0.9482472538948059)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('Blood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
